{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb16144b",
   "metadata": {},
   "source": [
    "# RAG With Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c89833",
   "metadata": {},
   "source": [
    "## Creating Indexed Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07003314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205375dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1054d27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x1dfb08e67b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bad98a",
   "metadata": {},
   "source": [
    "## Defining Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c14706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67337e",
   "metadata": {},
   "source": [
    "## Creating Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d4078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d31964",
   "metadata": {},
   "source": [
    "## Calling LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66451071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5e54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat_completion(\n",
    "    model= \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d47d6",
   "metadata": {},
   "source": [
    "## Complete RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b24f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a81fd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, I\\'ll answer your question.\\n\\nTo run Kafka, there are a few options based on the context:\\n\\n1. **Java Kafka:** To run Java-based Kafka components (producer/consumer/kstreams, etc.) in the terminal, you need to run the following command in the project directory:\\n\\n   ```bash\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\n   Make sure to replace `<jar_name>` with the actual name of your jar file.\\n\\n2. **Python Kafka:** \\n\\n   a. To run Python-based Kafka components, you first need to create a virtual environment by running the following commands (run only once):\\n\\n   ```bash\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\n```\\n\\n   For Windows, the path is slightly different: `env/Scripts/activate`.\\n\\n   To activate the virtual environment every time you need it, run:\\n\\n   ```bash\\nsource env/bin/activate\\n```\\n\\n   To deactivate it:\\n\\n   ```bash\\ndeactivate\\n```\\n\\n   Make sure Docker images are up and running before creating the virtual environment.\\n\\n   b. If you encounter the error \"Module ‘kafka’ not found,\" create a virtual environment as described above and run your Python files in that environment.\\n\\n   c. If you encounter the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\", use `pip install kafka-python-ng` instead of `pip install kafka` as suggested in the Kafka Python documentation.\\n\\n3. **Permission Denied Error:** If you encounter a \"Permission denied\" error when running `./build.sh`, run the following command in the terminal in the same directory:\\n\\n   ```bash\\nchmod +x build.sh\\n```\\n\\n   This should fix the error.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"How do I run Kafka?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605492c2",
   "metadata": {},
   "source": [
    "## Including Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37785ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "q_client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1505ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d043dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"zoomcamp-faq\"\n",
    "\n",
    "q_client.delete_collection(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2589160b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the collection with specified vector parameters\n",
    "q_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8280b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating points\n",
    "points = []\n",
    "\n",
    "for i,doc in enumerate(documents):\n",
    "\n",
    "    text = doc['question'] + ' ' + doc['text'] \n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=models.Document(text=doc['text'], model=model_handle), #embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "        payload=doc\n",
    "    )\n",
    "    \n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77d89b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointStruct(id=0, vector=Document(text=\"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", model='jinaai/jina-embeddings-v2-small-en', options=None), payload={'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52c7ef16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45897546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query):\n",
    "\n",
    "    vector_results = q_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        query_filter=models.Filter( # filter by course name\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=\"data-engineering-zoomcamp\")\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for point in vector_results.points:\n",
    "        results.append(point.payload)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b532453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'According to https://github.com/dpkp/kafka-python/\\n“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\\nUse pip install kafka-python-ng instead',\n",
       "  'section': 'Project',\n",
       "  'question': 'How to fix the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\"?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n—--------------------------------------------------------------------------------------\",\n",
       "  'section': 'Workshop 2 - RisingWave',\n",
       "  'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Use seed-kafka instead of stream-kafka to get a static set of results.',\n",
       "  'section': 'Workshop 2 - RisingWave',\n",
       "  'question': 'For the homework questions is there a specific number of records that have to be processed to obtain the final answer?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search(\"How do I run Kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3791a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vs_rag(query):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01791224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To run Kafka, follow these steps:\\n\\n1. **Verify the Bootstrap Server URL and Cluster Key/Secrets**:\\n   Ensure that in the scripts in `src/main/java/org/example/` (e.g., `JsonConsumer.java`, `JsonProducer.java`), the `StreamsConfig.BOOTSTRAP_SERVERS_CONFIG` is the correct server URL (e.g., `europe-west3` from example vs `europe-west2`). Also, make sure cluster key and secrets are updated in `src/main/java/org/example/Secrets.java` (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET).\\n\\n2. **Start the Kafka Broker Docker Container**:\\n   If you are using Docker containers for Kafka, use `docker ps` to confirm that the Kafka broker container is running. If it's not running, navigate to the `docker compose yaml` file folder and run `docker compose up -d` to start all the instances.\\n\\nThese are the general steps to run Kafka. If you encounter specific issues, refer to the provided solutions in the context.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_rag(query=\"How do I run Kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9a946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
